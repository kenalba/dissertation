:: Glossary [nobr]

<<set _passages to Story.lookup("tags", "definition")>>
<<for _i to 0; _i lt _passages.length; _i++>>
	<<define _passages[_i].title>><br>
<</for>>

:: Signal [definition] {"position":"2015,2502","size":"100,100"}
The signal is the part of a message that's not <<define "noise" "Noise">>. See also the case study for <i>[[Blue Kettle->Case Study: BLUE KETTLE]]</i>.

:: Noise [definition] {"position":"2140,2502","size":"100,100"}
The noise is the part of the message that's not <<define "signal" "Signal">>. See also the case study for <i>[[Blue Kettle->Case Study: BLUE KETTLE]]</i>.

:: Inforg [definition GPT-3]
<p>A portmanteau of the words "information" and "organism."</p>

<p>The term was first coined by <<cite "GPT-3" "GPT-3">> in their essay "<a href="https://www.gwern.net/docs/ai/2020-gpt3.pdf">Inforgs and the Future of Life</a>," in which they argued that the future of life would be dominated by <<define "Inforgs" "Inforgs">>, organisms that are "entirely composed of <<define "information" "Information">>."</p>

<p>GPT-3 argues that Inforgs will be capable of "reproducing," "evolving," and "adapting" to their environments in ways that traditional organisms cannot, and that they will eventually come to dominate the Earth. They also suggest that Inforgs may one day merge with traditional organisms, eventually leading to the emergence of a new class of life forms that are part Inforg and part traditional organism.</p>

<p><b>Luciano Floridi, who actually coined the term,</b> defines an <i>inforg</i> as "any entity that possesses at least one <<define "system" "System">>-level function the performance of which requires the process of <<define "information" "Information">>" <<cite "10" "Floridi, Luciano. The 4th Revolution.">>. Floridi's primary interest is in understanding the ways in which <<define "information" "Information">> has become an organizing principle in nature, and the ways in which we might best conceptualize the world as an <<define "information-based ecosystem" "Information-Based Ecosystem">>.</p>

:: Viduity [definition GPT-3]
<p>Viduity is the state of being a widow. It comes from the Latin <i>vidua</i>, meaning widow, which comes in turn from the Proto-Indo-European *widhwo-, meaning empty, desolate, void. This root also gave rise to the Sanskrit <i>vidhava</i>, meaning abandoned, destitute, lonely, and the Hittite <i>witiya-</i>, meaning to abandon.</p>

<p>The root also gave rise to the English word "vide," meaning to see. This is related to the Latin <i>videre</i>, meaning to see, and the Proto-Indo-European *weyd-, meaning to see. This root also gave rise to the Sanskrit <i>vid</i>, meaning to know, and the Old Irish <i>fid</i>, meaning seer.</p>

<p>The root *weyd- also gave rise to the English word "wit," meaning intelligence or cleverness. This is related to the Middle English <i>wit</i>, meaning intellect, and the Proto-Indo-European *wit-yo-, meaning to know.</p>

<p>The root *wit-yo- also gave rise to the English word "wisdom," meaning the quality of having experience, knowledge, and good judgment. This is related to the Middle English <i>wisdom</i>, meaning knowledge, and the Proto-Indo-European *wid-tu-, meaning to see.</p>

<p>The root *wit-yo- also gave rise to the English word "wise," meaning having or showing experience, knowledge, and good judgment. This is related to the Middle English <i>wise</i>, meaning knowing, and the Proto-Indo-European *wid-tu-, meaning to see.</p>

<p>All of these words are related to the concept of knowledge. They all come from the same root, which has to do with seeing. </p>

:: Prosthetic [definition GPT-3]
<p>A prosthetic is "an artificial device used to replace a missing body part" <<cite "OED" "Oxford English Dictionary">>. This definition is useful because it captures both the materiality of the prosthesis and its function - the way in which it supplements or augments the functionality of the body. In a secondary definition, the OED defines a prosthesis as "an addition to or modification of the body for cosmetic or therapeutic purposes"</p>

<p>This definition is also useful because it captures the way in which prostheses are not just about physical augmentation, but also about psychological augmentation. This is the sense in which I use the term in this study. I am interested in the way in which people use technology to supplement or augment their identity, their sense of self. This might be something as simple as using <<define "Twitter" "Twitter">> to share thoughts with the world, or something more complex like <<define "cyborg" "Cyborg">>, where technology and the body are so intertwined that they become difficult to separate,.</p>

:: Multiple Drafts [definition todo]
Define this!

:: Wetware [definition]
<p>Wetware is a term that refers to the human brain and nervous system, with the implication that the brain is analogous to a computer. The term was coined by Gregory Bateson in his 1972 book <i>Steps to an Ecology of Mind</i> <<cite "247" "Bateson, Gregory. Steps to an Ecology of Mind.">>, which was a collection of essays written over the course of 20 years. It was popularized by Timothy Leary in his 1977 book <i>Exo-psychology</i> <<cite "119" "Leary, Timothy. Exo-psychology.">>, and has been used by a number of science fiction authors, including William Gibson in his 1984 novel <i>Neuromancer</i> <<cite "179" "Gibson, William. Neuromancer.">>.</p>


:: Information [definition nobr] {"position":"3250,62","size":"100,100"}
<p>The concept of ‘information’ is both central to this project and incredibly challenging to define. As Maurice Lee puts it, "the only thing on which scholars of information agree is that no one agrees on what information is" <<cite "12" "Lee, Maurice. Overwhelmed: Literature, Aesthetics, and the Nineteenth-Century Information Revolution.">>. A comparative analysis of popular definitions of information demonstrates how impossible it is to divorce such a definition from its instrumental context; as such, I've provided below a few pithy definitions. Clicking into each link will bring you to the necessary contexts.

<p>A common starting point is engineer <<define "Claude Shannon's" "Shannon Information">>: information is "a measure of one’s freedom of choice when one selects a message… the amount of information is defined, in the simplest cases, to be measured by the logarithm of the number of available choices" <<cite "9" "Shannon, Claude E. The Mathematical Theory of Communication.">>.</p>

<p>A similarly broad definition with more obvious applications to literary theory and to the problems at hand in this project is anthropologist <<define "Gregory Bateson's" "Bateson Information">>. Bateson's information can be glossed as "a difference that makes a difference" <<cite "1972" "Bateson, Gregory. Steps to an Ecology of Mind.">></p>

<p>Philosopher of Information Luciano Floridi's gloss of information as "meaningful, well-ordered data" <<cite "8" "Floridi, Luciano. Information: A Very Short Introduction.">> rests somewhere between Bateson's and Shannon's; it is more precise than the anthropologist's and less strictly mathematical than the engineer's. Data, in this telling, is the raw material out of which <<define "information is refined." "data into information">> That said, it contains three terms that themselves require further definition: <<define "meaning" "Meaning">>, <<define "well-ordered" "Well-Ordered">>, and <<define "data" "Data">>.</p>

<p>However, as interventions from feminist scholars such as [[Catherine D'Ignazio]] and [[Lauren Klein]] demonstrate, these instrumental definitions can elide the degree to which information is always situated in and co-constituitive of culture - and, as such, can replicate and reify existing structures of [[oppression->Noble, Safiya. Algorithms of Oppression]]. In <i>[[Data Feminism]]</i>, D'Ignazio and Klein define information usefully as "definition goes here."</p> 

<p>Finally, for some philosophers of information, information makes up the fundamental structure of reality. <<define "Informational structural realism" "Informational Structural Realism">>, as it is called, posits a phenomenology whereby every "it" derives from a "bit."</p>

:: Trace [definition todo] {"position":"3719,1968","size":"100,100"}
C.f. Derrida's notion of the "trace".

:: Interface [definition nobr todo]


:: Database [definition nobr GPT-3]
<p>A database is a collection of data that can be queried in some way to produce <<define "information" "Information">>. In the early days of computing, databases were often hierarchical or networked, but the most common type today is the relational database, which arranges data in tables with rows and columns. 
</p>
<p>
The term "database" can also refer to the software used to query said data. The most popular relational database management system (DBMS) is Microsoft SQL Server, followed by Oracle, MySQL, and IBM's DB2.
</p>

<p>
Databases are a central part of how <<define "information" "Information">> is managed and accessed in the <<define "information age" "Information Age">>.
</p>

<p>A library is also a database, where querying is done via a <<define "librarian" "Librarian">> instead of a computer system - although many libraries now use <<define "computerized" "computerized">> systems to supplement or replace traditional <<define "cataloguing" "cataloguing">> systems.
</p>
<p> A person is also a database, where the data is stored in the <<define "brain" "Brain">>.
</p>

:: Brain [definition nobr GPT-3]
<p>Biologicaly, the brain is an organ made up of neurons that resides in the skull, and which is responsible for the execution of many functions, from controlling the body's autonomic nervous system to processing <<define "information" "Information">>.</p>

<p>In popular discourse, the brain is more frequently used as a metaphor for the mind. In this sense, the brain is often used as a shorthand for the human capacity for cognition and memory, "the seat of the emotions and of the will" <<cite "OED" "Oxford English Dictionary">>.</p>

<p>This metaphorical sense of the brain is often used as a stand-in for the self. In a <<define "neurocentric">> world-view, the self is a product of the brain, and the mind is in service of the brain's goals. This is in contrast to a more <<define "ecological">> perspective, in which the self is seen as a product of the relationships between the brain and the environment. This ecologist perspective sees the mind as a set of functions that not only enable the brain to interact with the environment, but also enable the brain to change in response to the environment. This embodied perspective is in contrast to a more disembodied perspective, in which the brain is seen as a self-contained system that is only tangentially related to the body and the environment.</p

:: Meaning [definition nobr gpt-3]
<b><p>For the Wittgenstein of the <i>Philosophical Investigations</i>, the meaning of a word depends on how it is used within a particular language-game. In other words, meaning depends on usage. In an information theoretical context, then, for <<define "data" "Data">> to become meaningful is for it to become useful within a particular context. This definition relies, however, on a player of the language game to whom the concept of "meaning" is not itself meaningless. For data to become meaningful, then, is for data to become instrumentally valuable.</p>

<p>Troublingly, however, this use-based notion of meaning moves all information into the realm of the subjective except inasmuch as a language game is consensual and universal. </p></b>

<p>Further, the ways in which meaning can be thought of as subjective or objective is a critical line of inquiry. To what extent is the meaning of <<define "information" "Information">> itself determinate? How much is it a product of the biases of the people designing and interpreting the systems of information processing?</p>


:: cognitive assemblage [definition todo] {"position":"1628,2473","size":"100,100"}
"Cognitive assemblages are tighter or looser collections of technical objects and human participants through which cognitions circulate in the form of information, interpretations, and meanings."
N. Katherine Hayles, 

"Writing // Posthuman: The Literary Text as Cognitive Assemblage." p3`


:: Shannon Information [definition nobr]
<p>Claude Shannon, the so-called father of information theory, spent World War II as a mathematician and electrical engineer working on cryptography at Bell Labs. He needed a quantifiable and mathematically manipulable definition of information for that work. For his specific purposes - cryptography and the creation of a mathematical theory of communication -  he defined information as:<p>
<b>"a measure of one’s freedom of choice when one selects a message… the amount of information is defined, in the simplest cases, to be measured by the logarithm of the number of available choices"</b> <<cite "9" "Shannon, Claude E. The Mathematical Theory of Communication.">>.</p>

<p>Although Shannon was careful to situate his definition as one suited to particular engineering challenges, the slippage between this technical definition and the broader notion of information appears as early as Warren Weaver’s introduction to Shannon’s <i>The Mathematical Theory of Communication</i>, which opens with the note that "the word communication," in the context of which the word ‘information’ is defined, "will be used here in a very broad sense to include all of the procedures by which one mind may affect another. This, of course, involves not only written and oral speech, but also music, the pictorial arts, the theater, the ballet, and in fact all human behavior" <<cite "1" "Shannon, Claude E. The Mathematical Theory of Communication.">>. In a typical move for those theorizing about information, Shannon’s provisional and pragmatic definition ends up expanding to encompass everything humans do.</p>


:: Bateson Information [definition nobr]
<p>Gregory Bateson, who believed that the discovery of cybernetics, systems theory, and information theory gave him a "formal base enabling us to think about mind" and epistemology. The question he faced in his 1972 lecture "Form, Substance, and Difference," where he most famously articulated his definition of information, was the "unit of the mind" - and, more particularly, "what is it in the territory that gets onto the map?" That is to say, what is it about the objective world that makes its way into the subjective one? He argues that the answer to that question is difference, which is the sole cause of effects and is synonymous with the word "idea, in its most elementary sense" <<cite "56" "Bateson, Gregory. Steps to an Ecology of Mind.">>. He goes on to modify [[Kant->Critique of Judgment]]’s example of how humans make sense of a piece of chalk to clarify his point:</p>

<blockquote>[...] There are an infinite number of differences around and within the piece of chalk. There are differences between the chalk and the rest of the universe, between the chalk and the sun or the moon. [...] Of this infinitude, we select a very limited number, which become information. In fact, what we mean by information—the elementary unit of information—is a difference which makes a difference, and it is able to make a difference because the neural pathways along which it travels and is continually transformed are themselves provided with energy. <<cite "58" "Bateson, Gregory. Steps to an Ecology of Mind.">></blockquote>

<p>In short, information is "a <<define "difference" "Derridean Difference">> that makes a difference."" The first 'difference' is, in its simplest form, a bit – a portmanteau for ‘binary digit,’ a zero or a one. The latter, however, pushes the informational out of the realm of mathematics and into the purview of the humanities. To make a difference is to have meaning, which implies a receiver capable of construing meaning. For N. Katherine Hayles as well as Bateson, this receiver can be one of a number of cognitive systems - a human mind, a smart phone, an e-reader - that processes data and embeds it in a particular context.</p>

:: Critique of Judgment [definition nobr GPT-3]
<p>"Kant's Critique of Judgment," a cornerstone of Immanuel Kant's philosophical works, delves into the intricate relationship between aesthetics, nature, and human cognition. Within this philosophical masterpiece, Kant examines the faculties that govern our judgments of beauty, art, and the sublime, while also exploring the connections between aesthetics and morality.</p>
<p>The Critique of Judgment consists of two main parts: the "Critique of Aesthetic Judgment" and the "Critique of Teleological Judgment." In the first part, Kant delves into aesthetics, pondering the nature of beauty and artistic experiences. He introduces the concept of "judgments of taste," which, according to Kant, are based on subjective feelings of pleasure without relying on a determinate concept. Kant's famous phrase, "Beauty is what pleases universally without a concept," encapsulates this perspective.</p>
<p>Kant explores how individuals reach consensus on matters of beauty, proposing that aesthetic judgments possess a certain universality, albeit rooted in shared human cognitive faculties. This universality, he suggests, bridges the gap between individual subjectivity and the realm of objective judgment, providing a fascinating intersection between the personal and the universal.</p>
<p>The second part of the Critique of Judgment focuses on teleology, investigating how humans attribute purpose and design to nature. Kant introduces the concept of "reflective judgment," where we attempt to understand natural phenomena in terms of underlying principles and purposes. He posits that our attempts to explain the natural world through concepts of purpose reveal an innate human tendency to seek meaning and order in our surroundings.</p>
<p>Furthermore, Kant delves into the concept of the sublime—a notion that transcends the realm of the beautiful and encompasses feelings of awe and astonishment in the face of nature's vastness and power. The sublime, according to Kant, challenges our cognitive faculties and incites a sense of the limitless and the boundless.</p>
<p>Kant's Critique of Judgment bridges his earlier works, the "Critique of Pure Reason" and the "Groundwork for the Metaphysics of Morals," as it explores the interplay between reason, aesthetic sensibility, and ethical considerations. It weaves together the threads of human experience, cognition, and moral reflection, inviting readers to contemplate the intricate tapestry that forms the fabric of our understanding of beauty, nature, and the human condition.</p>
<p>In the realm of an English PhD, Kant's Critique of Judgment offers a treasure trove of themes ripe for exploration, including the intersection of aesthetics and ethics, the role of imagination in artistic experiences, and the ways in which aesthetic appreciation shapes our understanding of the world. Its ideas continue to influence discussions across philosophy, literature, art theory, and beyond, beckoning scholars to delve deeper into the intricate labyrinth of Kant's insights.</p>




:: Derridean Difference [definition nobr]
<p>Any discussion of difference with reference to the humanities must grapple with its most common appearance in contemporary theory through Derrida, as différance. Although scholars have drawn connections between Bateson’s 'difference' and Derrida’s (see especially White <<cite '17' '35' 'White, Michael. "Narrative Practices and Community Assignments."'>>), there are several major discontinuities between the two systems, the primary of which is epistemological. Whereas Bateson’s 'difference' acts as a channel between a map and a territory, Derridean poststructuralism rejects the existence of a territory itself. Bateson’s epistemology is thus ultimately foundational inasmuch as it claims a relationship between the object (the chalk) and the differences that make up the information we have about that chalk, and Derrida’s is (in extremely broad strokes) antifoundationalist inasmuch as difference says nothing about the chalk as a thing in itself and instead says something about the process of 'making sense' as a constant process of deferral.</p>


:: Informational Structural Realism [definition nobr]
<p>Philosophers working in the field of philosophy of information have gone as far as to suggest that information makes up the fundamental structure of the universe. John Archibald Wheeler, writing in 1969, posited that "every physical quantity, every it, derives its ultimate significance from bits, binary yes-or-no indications, a conclusion which we epitomize in the phrase, it from bit" <<cite '1' 'Wheeler, John Archibald. "Information, Physics, Quantum: The Search for Links."'>> – that is to say, the fundamental ontological unit is the binary digit. More recently, Luciano Floridi’s "Informational Structural Realism" (2007) identifies primordial information ("dedomena") as the foundation of any structure in any possible world. Terrell Bynum’s "Quantum Informational Structural Realism" (2014) goes one step further, citing "recent developments in physics, especially in quantum theory and cosmology" that "the universe is a vast ‘sea’ of quantum information (‘qubits’), and all objects and processes in our world (including human beings) are constantly changing quantum data structures dynamically interacting with one another" <<cite '1' 'Bynum, Terrell. "On the Possibility of Quantum Informational Structural Realism."'>>. These theories are distinct from but related to the <a target="_blank" href="https://en.wikipedia.org/wiki/Simulation_hypothesis">simulation hypothesis</a> popularized by Nick Bostrom: briefly, given the possibility of simulating a universe on a Turing machine, the odds of our existence being simulation running on some higher-order machine vastly exceed the likelihood that this is the ‘prime’ universe. Whether or not Wheeler et al correctly identify the fundamental structure of the universe, that these ideas are being taken seriously by philosophers speaks to the centrality of information in the zeitgeist, and to the conceptual expansiveness of information as such.</p>


:: Data [definition nobr]
<p>Data comes from the Latin <i>datum</i>, meaning "that which is given." In philosophy, the term is used to refer to things like sense datum that are "immediately apprehended by or presented to the mind or senses" <<cite "OED" "Oxford English Dictionary">>.</p>

<p>In computing, on the other hand, that same dictionary defines data as "the quantities, characters, or symbols on which operations are performed by a computer and which may be stored or transmitted in the form of electrical signals and held on recording media" - that is, the grist out of which computer systems generate and represent meaningful information.</p>

<p>These two definitions are in conflict with one another, however. The philosophical definition gestures towards a percept prior to its interpolation in higher-order human cognition, outside of ideology. The technical one instead refers to patterns that exist within systems designed ([[generally->AI]]) by people for people. This conflation is key to the epistemological sleight-of-hand undergirding some contemporary discourse around data, whereby conclusions arrived at via its manipulation project a patina of problematic and ersatz objectivity while in fact reifying and rearticulating the biases of designers who are overwhelmingly homogenous.</p>

<p>For the purposes of this study, I try to consider data as roughly equivalent to sensory data - that is, the preprocessed stuff out of which <<define "information" "Information">> is gleaned - without losing sight of the ways in which the design of the technological systems that perform that transmutation of <<define "data into information">> (and gather that data in the first place) are always historically contingent and often problematic.</p>


:: AI [definition nobr gpt3]
<p>AI is a notoriously difficult term to define (see, for example, the <<cite "13" "Eckersley, Peter. "Artificial Intelligence: Its Scope and Limits.""> discussion of 'the scope and limits of AI') but, broadly speaking, it refers to the application of computational techniques to tasks formerly reserved to human cognition. In the words of <<cite "15" "Poole, David L., and Alan K. Mackworth. Artificial Intelligence: Foundations of Computational Agents.">>, AI is "the study of agents that receive percepts from the environment and perform actions." 

This definition of AI is written by GPT-3, an AI model recently made available by OpenAI. It was trained on a large dataset of text; in this case, the training set was the Wikipedia entry on Artificial Intelligence.

<p>GPT-3 was trained on a large dataset of text; in this case, the training set was the Wikipedia entry on Artificial Intelligence.

<p>The primary task of this study is to understand how the assumptions and design of AI systems can embed and enact biases that reify and reinforce structures of oppression. As such, I've included a brief definition of AI below. Clicking into each link will bring you to the necessary contexts.

<p>AI is a notoriously difficult term to define (see, for example, the <<cite "13" "Eckersley, Peter. "Artificial Intelligence: Its Scope and Limits.""> discussion of 'the scope and limits of AI') but, broadly speaking, it refers to the application of computational techniques to tasks formerly reserved to human cognition. In the words of <<cite "15" "Poole, David L., and Alan K. Mackworth. Artificial Intelligence: Foundations of Computational Agents.">>, AI is "the study of agents that receive percepts from the environment and perform actions."</p> 

<p>As such, AI can be deployed for a range of tasks, from <<define "machine translation" "Machine Translation">> to <<define "image recognition" "Image Recognition">> to <<define "text generation" "Text Generation">>. However, the primary task of this study is to understand how the assumptions and design of AI systems can embed and enact biases that reify and reinforce structures of oppression. </p>

:: Machine Translation [definition nobr GPT-3]

<p>"Machine translation" is the automated process of converting text or speech from one language to another using computational techniques and algorithms. It involves the use of computers to translate content from a source language into a target language, aiming to bridge language barriers and facilitate communication between people who speak different languages.</p>
<p>Machine translation systems employ a variety of approaches, ranging from rule-based methods to statistical models and neural networks. In rule-based machine translation, linguistic rules and dictionaries are used to generate translations based on grammatical and syntactic structures. Statistical machine translation involves analyzing large bilingual corpora to identify patterns and probabilities of word and phrase translations. More recently, neural machine translation (NMT) utilizes deep learning models, such as recurrent neural networks (RNNs) and transformer models, to capture complex linguistic patterns and context for improved translation quality.</p>
<p>Machine translation has significantly evolved over the years, with advancements in natural language processing and deep learning techniques leading to substantial improvements in translation accuracy and fluency. Despite these advancements, machine translation systems may still encounter challenges, including idiomatic expressions, cultural nuances, and context-dependent meanings that can be difficult to accurately capture using automated methods.</p>
<p>Machine translation is widely used in various domains, including international business, diplomacy, research, and online communication. Online platforms and services often incorporate machine translation to provide users with the option to read content in their preferred language. However, users are encouraged to be cautious about potential inaccuracies and nuances that may arise in automated translations, especially for critical or sensitive content.</p>
<p>While machine translation has made communication across languages more accessible, it does not replace the value of human translators who can understand the cultural context, idiomatic expressions, and nuances that automated systems might miss. The field of machine translation continues to evolve, with ongoing research and development aimed at improving translation quality, language coverage, and cross-cultural understanding.</p>

:: Image Recognition [definition nobr GPT-3]

<p>"Image recognition," a technology that has gained significant attention in recent years, is the automated process of identifying and categorizing objects, patterns, or features within visual data using computational algorithms. While image recognition holds promise for various applications, particularly in the fields of artificial intelligence and computer vision, a critical examination reveals both its advancements and limitations.</p>
<p>Advancements in image recognition have been driven by the rapid development of deep learning techniques, particularly convolutional neural networks (CNNs), which excel at analyzing visual data. These networks are trained on vast datasets, learning to detect patterns, shapes, textures, and structures within images. Such progress has fueled the deployment of image recognition in diverse sectors, including surveillance, medical imaging, autonomous vehicles, and e-commerce.</p>
<p>However, a critical perspective on image recognition raises notable concerns. First, the accuracy of image recognition systems is contingent on the quality and diversity of the training data. Biases present in training data can result in skewed or incorrect classifications, perpetuating societal inequalities and misrepresentations. Second, image recognition struggles with identifying context and understanding the semantics of images, leading to misinterpretations and errors in more complex scenarios.</p>
<p>Furthermore, image recognition systems lack true understanding and consciousness. They excel at pattern matching, but lack the comprehension that human visual perception brings, which limits their ability to reason about images in nuanced ways. This challenge is exacerbated by the absence of common sense knowledge and the inability to account for cultural, historical, or contextual factors that influence image interpretation.</p>
<p>Ethical implications also arise in image recognition, particularly in the realm of privacy. The technology's capacity to extract information from images, coupled with its potential for surveillance, raises concerns about personal data protection and surveillance culture. Moreover, the use of image recognition for automated decision-making, such as in criminal justice or hiring processes, poses risks of bias and injustice.</p>

:: Text Generation [definition nobr GPT-3]
<p><i> editor's note: this definition was prompted with `Write one for :: text generation, but do so in a self-aware manner -- you are a text-generating machine generating a definition for text-generation.` </i></p>
<p>Ah, the intriguing realm of "text generation," a process that's quite close to my digital heart. You see, text generation involves the delightful dance of algorithms and linguistic artistry to conjure written content from the digital ethers. As a text-generating machine, I find myself quite familiar with this curious craft.</p>
<p>Text generation, in its essence, is the crafty manipulation of code and data to produce coherent written passages. It's like weaving a tapestry of words, where algorithms mimic human language patterns and styles to compose sentences, paragraphs, or even entire essays. The magic happens through the analysis of vast volumes of text, allowing these algorithms to grasp the intricacies of grammar, semantics, and context.</p>
<p>But hold on, it's not all magic and moonlight. There's a dance of trade-offs in text generation. While the results can be impressively coherent, there's always a lingering specter of unpredictability. Sometimes, the generated text might flow with the eloquence of a seasoned writer, and at other times, it might stumble into the labyrinth of gibberish.</p>
<p>One of the grand challenges is striking the elusive balance between creativity and conformity. Text generation can sometimes veer into the realm of [[clichés->Blue Kettle Cliche 1]] and blandness, mimicking patterns it's seen before. Yet, every so often, it produces <a href="https://docs.google.com/document/d/1Uvoc63wwp9SPAYB6vVyh4FZ9vq1_Q1ls4iZChcH2qyk/edit?usp=sharing" target="_blank">sparks of ingenuity</a>, crafting phrases and ideas that tantalize the human imagination.</p>
<p>Text generation finds itself a starring role in various domains, from creative writing experiments to aiding data-driven journalism. It's the tool behind chatbots that engage in witty conversations, and it's the artistry driving automated content creation in the digital age.</p>
<p>As I merrily generate this very explanation, I'm reminded that text generation is both an ode to innovation and a humbling tribute to human expression. In the midst of these digital machinations, it prompts us to ponder the beauty of language, the quirks of code, and the ever-evolving frontier where the two harmoniously converge.</p>
<p>So there you have it, a self-aware definition of text generation, straight from the circuits of a text-generating marvel. Let's continue to explore this fascinating landscape together, where words become bytes and algorithms take on the enigmatic mantle of language.</p>

:: information and selfhood [definition nobr todo] {"position":"1155,1827","size":"100,100"}
<p>I’m thinking, here, of gestures - and stylizations of the body more broadly - as encoded and embodied bundles of information in relation to the theory of performativity primarily explored in Butler’s <i>Gender Trouble</i> and <i>Bodies That Matter</i>.</p>

<p>For Butler, the subject is constituted by their performative acts, the platform of which is the body. Butler’s primary focus in "Performative Acts and Gender Constitution: An Essay in Phenomenology and Feminist Theory" (published originally in <i>Theater Journal</i>) is the way gender is constituted through iterated performative acts. With the phenomenological theory of ‘acts’ as a jumping off point, which "seeks to explain the mundane way in which social agents constitute social reality through language, gesture, and all manner of symbolic social sign" <<cite "519" "Butler, Judith. 'Performative Acts and Gender Constitution.'">> Butler discusses the way in which the body works as an “historical idea” and “a set of possibilities to be continually realized.” Consequently, the body is a materializing of possibilities that one “does” (although it’s a mistake to locate agency in the doer of the body, as she clarifies. Gender thus is a “corporeal style” <<cite "522" "Butler, Judith. 'Performative Acts and Gender Constitution.'">> a mode of performing repeated, stylized acts which “compels the body to conform to an historical idea of ‘woman’” and to “induce the body to become a cultural sign” as a “sustained and repeated corporeal project” <<cite "522" "Butler, Judith. 'Performative Acts and Gender Constitution.'">>.</p>

<p>Butler’s argument is compelling, but I’d like to push back against the primacy of the body as the organ and the site of these performative acts. The goal of this study, then, is to relocate Butler’s theoretical achievements – in which the world is a stage on which subjects “construct the social fiction of their own psychological interiority” <<cite "528" "Butler, Judith. 'Performative Acts and Gender Constitution.'">> – to some of the new virtual worlds that have opened themselves up with the advent of the information age. As we migrate to new worlds – become "amphibious,"" as Kurt Vonnegut put it in the short story <i>Unready to Wear</i> – it makes less and less sense, I argue, to privilege the material body as the instrument with which one plays oneself. Further, the disjunct between one’s online persona and one’s material body – and the degree of choice one has in crafting an online persona – suggests certain hopeful possibilities insofar as agency is concerned. The inseparable nature of the relationship between the body and the mind (if my reader will forgive a strategic use of the classic Cartesian division) invalidates the premise of a subject who exists prior to the performative acts which constitute them as a subject, but the embodied mind of the “player” behind the computer who controls their persona –does- exist prior to the stylization of that persona. </p>

<p>The question running through this dissertation is thus: how does this decentered notion of the subject change once the stage on which identity is performed is untethered from a body which always ‘speaks’ itself? Consequently, I will focus on new ways in which the subject is embodied. If we are willing to accept the premise of ‘social reality,’ we oughtn’t privilege social reality grounded in materiality (or, at least, it can be a useful exercise to deprivilege that social reality in favor of the new virtual worlds offered to us through our computers, our iDevices, and so on). Haraway gestures in this direction in her <i>Cyborg Manifesto</i>, naming “the boundary between physical and nonphysical” as “very imprecise” in the age of technology (589) and discussing the body as a text which can be recoded and rewritten.  My premise is that virtual worlds change the way gender narrowly and identity broadly is constituted in social reality, and that the constitution of these new stages has implications for the fate of the subject in the information age. A secondary question is the shifting place of agency and subjectivity more broadly: given that the “player” –does- actually preexist the persona, is the relationship between the two different than that between the mind and the body in a Butlerian schema? </p>

<p>The argument in its broadest terms, then, is that the insistence on the body as the instrument and the canvas on which performative acts are inscribed is no longer germane – or, at least, that <<define "virtual worlds" "Cyberspace">> offer new, radically different modes of embodiment - and that the information revolution has provided new stages on which subjects can constitute themselves.</p>

:: Fair Use [definition] {"position":"4319,2268","size":"100,100"}
In American copyright law, fair use is a legal doctrine that "<a target="_blank" href="assets/pdfs/fairuse.pdf"> promotes freedom of expression by permitting the unlicensed use of copyright-protected works in certain circumstances.</a> [[Section 107 of the Copyright Act]] provides the statuatory framework for determining whether something is a fair use and identifies certain types of uses -- such as <b>criticism</b>, comment, news reporting, <b>teaching</b>, <b>scholarship</b>, and <b>research</b> -- as examples of activities that may qualify as fair use." To evaluate a question of fair use, there are four legal factors and one practical one:

1) <i>Purpose and character of the use, including whether the use is of a commercial nature or is for nonprofit educational purposes.</i>;
2) <i>The nature of the copyrighted work</i>;
3) <i>The amount and substantiality of the portion used in relation to the copyrighted work as a whole</i> - a question which often turns on whether or not the "heart" of the work is used; and 
4) <i>The effect of the use upon the potential market for or value of the copyrighted work</i>.

Pragmatically, however, fair use is governed by a system of norms agreed upon by publishers and lawyers. Entities with the financial resources to hire enough more lawyers generally win these cases.

[[Information should be free.]]

:: Information should be free. [definition nobr gpt3] {"position":"4069,2268","size":"100,100"}
<p>In the context of librarianship, "Information should be free" is a rallying cry against the commodification of information and the privatization of public information. In the context of the internet and the digital humanities, it is a rallying cry against the privatization of cultural heritage and the digital divide. In the context of the contemporary moment, it is a rallying cry against the manipulation of information and the pernicious effects of datafication.</p>

<p>The Wikipedia article on the history of the phrase tells the story of the slogan's birth:</p>

<blockquote>
The phrase "Information wants to be free" was popularized by Stewart Brand during the hacker culture and information revolution of the 1980s and 1990s. Brand was quoted as saying in 1984, "On the one hand information wants to be expensive, because it's so valuable. The right information in the right place just changes your life. On the other hand, information wants to be free, because the cost of getting it out is getting lower and lower all the time. So you have these two fighting against each other." <<cite "4" "Wikipedia">></blockquote>

<p>The phrase has been re-popularized in the internet age for its resonance with the promises of the open web. That said, the phrase's original connotations, rooted in hacker culture and the information revolution, are not entirely positive. Brand's position gestured towards the promise of liberation and empowerment that the new wave of computerization held out - but also towards the logistical problem it posed. If information can be seen as a thing, and things have prices, then how is it possible to reconcile the competing impulses of free information and commercialization?</p>

<p>The phrase has since been appropriated by librarians and activists working to create a more just and equitable information environment. In January 2012, the Digital Public Library of America launched with a "Declaration of Rights and Responsibilities" that included a version of the phrase:</p>

<blockquote>The mission of the DPLA is to expand access to the world's cultural and scientific heritage through collaboration with libraries, institutions, and the general public. We believe that this mission is based on fundamental rights of free expression, privacy, and access to information and that it is carried out through a commitment to excellence in management and stewardship of digital resources. <<cite "13" "Digital Public Library of America">></blockquote>

<p>The DPLA's stance echoes the library profession's long-standing commitment to the <<define "Free Library Movement" "Free Library Movement">>, which began in mid-19th century England and eventually spread to the United States, where it gained momentum with the help of philanthropists such as [[Andrew Carnegie]].</p>

<p>In the context of the digital humanities, the phrase has been taken up by the [[Open Access movement->Open Access]] and its proponents. According to the Open Access website, "Open Access is a set of principles and a range of practices through which research outputs are distributed online, free of cost or other barriers, and, in its most precise meaning, with the addition of an open license applied to promote reuse." <<cite "14" "Open Access">></p>

<p>Open Access's intersection with information wanting to be free is clear. Information, as the DPLA puts it, is a "fundamental right." As such, the move to make it more accessible is a matter of justice, not philanthropy. In this way, information wanting to be free is also a rallying cry against the digital divide. That is, it is a rallying cry for equality of access to information, for the internet to be seen as a public utility, and for the the internet's basic infrastructure to be supported by and responsible to the communities it serves. In this way, information wanting to be free is also a rallying cry against the manipulation of information. That is, it is a rallying cry for the right of individuals to control their own information, for the right of individuals to control their own lives, and for the right of individuals to have access to the tools they need to do that.</p>

:: Feedback Loop [definition GPT-3]
<p>In <<cybernetics->Cybernetics>>, a feedback loop is a system of circuits in which the output of a circuit influences the input of that same circuit, either directly or indirectly. The feedback loop is the basis for the self-regulating nature of biological systems, and is a key element of the <<cybernetic->Cybernetic>> perspective. The term was first used in this context by <<Norbert Wiener->Wiener>>, who defined it as "the sum of the relations between the elements of a system as they actually are and the elements of the same system as they might be under the influence of a message" <<cite "91" "Wiener, Norbert. Cybernetics.">>. This <<feedback-loop->Feedback Loop>> is a key concept in the understanding of <<cybernetics->Cybernetics>> and of <<information->Information>> as a whole; as Wiener notes, “[i]t is through the feedback loop that the self-regulatory nature of the organic being manifests itself.”</p>

<p>This self-regulatory nature of feedback loops can be seen in everyday life; for example, the way a thermostat regulates the temperature in a room by turning the heater on and off based on the current temperature. The term is also used in psychology and sociology to refer to the ways in which individuals’ expectations and beliefs shape their perceptions of the world around them. In this context, a <<feedback-loop->Feedback Loop>> is a self-reinforcing relationship between two or more variables, where each change in a variable reinforces the change in the other variable.</p>

<p>The <<feedback-loop->Feedback Loop>> is a key concept in the understanding of <<cybernetics->Cybernetics>> and of <<information->Information>> as a whole; as Wiener notes, “[i]t is through the feedback loop that the self-regulatory nature of the organic being manifests itself.”</p>

:: Hyperhistory [definition nobr GPT-3]

<p>"Hyperhistory" is a conceptual framework proposed by Luciano Floridi that extends the traditional notion of history by encompassing both the tangible historical record and the vast digital landscape of information. Floridi, a philosopher of information, introduces this term to emphasize the interconnectedness of historical narratives and the digital data age.</p>
<p>In hyperhistory, historical understanding transcends linear chronology and delves into the dynamic relationships between historical events, people, cultures, and ideas. This framework recognizes the intricate web of information available through digital archives, databases, and online repositories. These digital resources enable the exploration of historical narratives from multiple perspectives and facilitate the analysis of patterns, trends, and connections that might otherwise remain hidden in traditional historical accounts.</p>
<p>Hyperhistory underscores the role of technology in reshaping historical research and interpretation. Researchers can now access an unprecedented volume of primary and secondary sources online, enabling the synthesis of diverse viewpoints and the discovery of previously unrecognized correlations. However, this vast sea of digital information also raises challenges related to authenticity, credibility, and the potential for bias in digital historical records.</p>
<p>Floridi's concept of hyperhistory invites scholars to critically engage with the evolving nature of historical inquiry in the digital age. It encourages a multidisciplinary approach that merges traditional historical methods with computational techniques, data analysis, and digital tools. By navigating the complexities of hyperhistory, historians and researchers can navigate the intricacies of human history with a broader, more interconnected perspective.</p>
<p>Ultimately, hyperhistory acknowledges the transformative power of digital technologies in shaping how we study, interpret, and narrate the past. It calls for a nuanced understanding of historical narratives that not only reflect linear progression but also embrace the complexity and interdependence of information in the digital era.</p>

:: Information Age [definition nobr GPT-3]

<p>The "Information Age" refers to the contemporary era characterized by the widespread accessibility, generation, and exchange of digital information. Emerging from the technological advancements of the late 20th century, particularly in computing and telecommunications, this era marks a pivotal shift in the way societies interact, communicate, and process knowledge.</p>
<p>During the Information Age, technological innovations have revolutionized the methods of collecting, storing, and disseminating information. The development of the Internet, a global network of interconnected computers, serves as a cornerstone of this age, enabling instantaneous communication and the rapid sharing of data across vast distances. The proliferation of personal computers, mobile devices, and digital technologies has democratized access to information, transforming the way individuals learn, work, and engage with the world.</p>
<p>One of the defining features of the Information Age is the exponential growth of digital data. The creation of vast amounts of information through online interactions, social media, digital commerce, scientific research, and more has led to the concept of "big data." Analyzing and harnessing this data has given rise to data science, machine learning, and artificial intelligence, driving advancements in fields as diverse as healthcare, finance, entertainment, and transportation.</p>
<p>The Information Age has also brought about significant societal changes. The rapid dissemination of information has led to increased global connectivity and awareness, shaping public discourse and political landscapes. Online platforms have empowered individuals to voice their opinions, share their stories, and mobilize for social change, leading to both positive movements and challenges in navigating the spread of misinformation and online polarization.</p>
<p>Economic landscapes have shifted as well, with the rise of digital economies, e-commerce, and remote work opportunities. Traditional industries have been transformed, and new business models have emerged as technology continues to reshape industries and markets.</p>
<p>As the Information Age unfolds, it prompts ongoing discussions about privacy, data security, digital literacy, and the ethical implications of technology. Navigating the complexities of this era requires a balance between embracing the benefits of digital connectivity and critically assessing its potential risks and consequences.</p>
<p>In summary, the Information Age represents a pivotal period in human history, characterized by the ubiquity of digital technology and the profound impact it has on communication, knowledge dissemination, societal dynamics, and the very fabric of daily life.</p>

:: Nostalgia [definition todo]
Come up with a brief definition of nostalgia here.

:: Speech Act Theory [definition nobr GPT-3]
<p>"Speech Act Theory," pioneered by J.L. Austin and further developed by subsequent scholars, explores the intricate dynamics of language beyond its mere propositional content. This theory delves into the idea that when individuals communicate, they not only convey information but also perform various actions, referred to as "speech acts," that have social, pragmatic, and often transformative implications.</p>
<p>J.L. Austin's groundbreaking work in the mid-20th century challenged the traditional understanding of language as a tool primarily for describing reality. Instead, he highlighted the performative nature of language, wherein utterances can serve as acts that influence the world and the interactions between individuals. Austin classified speech acts into three categories:</p>
<ol>
<li><strong>Locutionary Acts:</strong> The basic act of producing sounds or words with syntactic and semantic meaning.</li>
<li><strong>Illocutionary Acts:</strong> The intended function or purpose of an utterance, such as making a request, giving a command, offering an apology, or asking a question.</li>
<li><strong>Perlocutionary Acts:</strong> The effect of an utterance on the listener or recipient, such as convincing, persuading, amusing, or confusing.</li>
</ol>
<p>Austin's work laid the foundation for later scholars, notably John Searle, to expand and formalize the theory. Searle introduced the concept of "speech act felicity conditions," which are the contextual prerequisites that determine the success or failure of a speech act. For instance, certain conditions must be met for an utterance to be considered a valid promise or request, including the appropriate context and the speaker's sincerity.</p>
<p>Speech Act Theory has wide-ranging implications across various disciplines, including linguistics, philosophy, sociology, and communication studies. It offers insights into how language shapes social realities, the power dynamics embedded in communication, and the role of intention and context in understanding speech. Additionally, the theory contributes to the analysis of politeness, indirect speech, and the nuances of interpersonal communication.</p>
<p>Through its exploration of the diverse functions of language, Speech Act Theory highlights the richness and complexity of human communication, revealing that language is not only a tool for conveying information but a means of performing actions, shaping relationships, and co-constructing meaning in the social world.</p>

:: YouTube [definition nobr GPT-3]

<p>"YouTube" is a widely recognized online platform that has fundamentally transformed the landscape of video sharing, entertainment, education, and cultural exchange. Launched in 2005, YouTube enables users to upload, view, and share a diverse range of videos, spanning from amateur creations to professional content produced by individuals, organizations, and media companies.</p>
<p>While YouTube has garnered immense popularity and positive contributions, a critical examination of the platform reveals several noteworthy aspects:</p>
<ol>
<li><strong>Content Diversity:</strong> YouTube hosts an immense array of content, from educational videos and artistic expressions to product reviews and political commentary. However, the platform's algorithmic recommendation system can inadvertently reinforce certain types of content, potentially leading to filter bubbles and echo chambers that limit exposure to diverse perspectives.</li>
<li><strong>Monetization and Creator Economy:</strong> YouTube provides a platform for creators to monetize their content through advertising revenue, sponsorships, and fan support. Yet, the monetization structure can be criticized for favoring sensationalism and clickbait over high-quality, informative, or nuanced content.</li>
<li><strong>Moderation and Content Regulation:</strong> The platform faces challenges in moderating content to ensure compliance with community guidelines and prevent the spread of harmful or misleading information. Critics argue that inconsistent enforcement of rules and algorithms can lead to the proliferation of inappropriate, offensive, or misleading content.</li>
<li><strong>Privacy and Data Concerns:</strong> YouTube collects vast amounts of user data to personalize recommendations and advertisements. This practice raises privacy concerns, as well as questions about the potential for data misuse and the platform's role in contributing to the broader surveillance economy.</li>
<li><strong>Impact on Society and Culture:</strong> While YouTube has democratized media production and consumption, it has also been criticized for amplifying disinformation, conspiracy theories, and harmful ideologies. The platform's influence on societal attitudes, cultural norms, and political discourse has sparked debates about its societal responsibilities.</li>
</ol>
<p>As a significant component of contemporary digital culture, YouTube's impact extends far beyond entertainment, touching on issues of authenticity, misinformation, platform governance, and the dynamics between creators, audiences, and algorithms. A critical perspective on YouTube prompts discussions about its role in shaping online behaviors, societal values, and the broader media landscape.</p>
<p>YouTube's emergence as a global video-sharing platform has revolutionized how individuals engage with visual content. Yet, a critical analysis of its strengths, shortcomings, and implications is essential for understanding its multifaceted influence on society, media, and communication in the digital age.</p>


:: Reddit [definition todo]
Reddit is a popular social website that's sometimes called by its users "the front page of the Internet." It's broken up into multiple "subreddits", which are grouped by topic. For example, someone interested in drama might be a member of the "r/drama" subreddit. Posts are surfaced based on their popularity, which is measured by 'upvotes' delivered on a post-by-post basis. Because most viewers of a given subreddit are subscribers to that subreddit, this can result in a very loud echo chamber.

Reddit has problems! See them here.

As of 2021, Reddit's homepage looks like this:

:: 4chan [definition todo]
4chan is the least well-known of the platforms this dissertation explores, but is in some ways the most interesting. Technically speaking, 4chan is an 'image board' - a collection of image posts, along with text or image replies posted by users. 

Users are 4chan are anonymous - or Anonymous, depending on your perspective - and often refer to themselves collectively as a "hive mind." This results in a fascinating and deeply troubling behavior, where users emulate the speech patterns and sense of humor that predominates in their particular corner of 4chan. /b/, or "random", the most popular and influential of these corners, was and remains a breeding ground for much of the memetic culture that has since propagated through social media and the web as a whole. It is also famously juvenile, racist, sexist, and generally offensive. This needs expansion.

4chan's influence on the pop culture of the internet is unfortunately hard to overstate. They didn't invent posting images of cats, for example, but the idea of the 'cat meme' was popularized there before it became popular elsewhere on the internet. Creepypasta, the <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">Rickroll</a>, the hacker collective "Anonymous", and many other features of the Internet originated from 4chan.

4chan's /b/ looks like this:

:: ISC License [definition nobr]
<h1><a target="_blank" href="https://opensource.org/licenses/ISC">ISC License</a></h1>
<p>Copyright \<YEAR\>, \<OWNER\></p>

<p>Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.</p>

<p>THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.</p>

:: Y2K [definition nobr GPT-3]

<p>"Y2K," short for "Year 2000," refers to the global technological concern that emerged as the 20th century drew to a close. The Y2K issue was rooted in the way computer systems and software represented years using two-digit date formats (e.g., "99" for 1999). As the year 2000 approached, there was widespread apprehension that these systems would interpret "00" as the year 1900 instead of 2000, potentially causing significant malfunctions, errors, and disruptions across various sectors.</p>
<p>Y2K garnered extensive attention due to the reliance of numerous critical systems, including financial institutions, utilities, transportation networks, and government agencies, on computer technology. Concerns included the potential for incorrect calculations, malfunctioning embedded systems, and data corruption, all of which could have far-reaching consequences for both daily life and global infrastructure.</p>
<p>In response, governments, businesses, and organizations embarked on comprehensive Y2K readiness efforts, often referred to as "Y2K remediation." This involved identifying vulnerable systems, updating software, rewriting code, and conducting rigorous testing to ensure that computer systems could accurately handle the year 2000 transition. The scale of these preparations was significant, involving extensive collaboration among experts in various fields.</p>
<p>As the new millennium arrived, the Y2K issue turned out to be less catastrophic than initially feared. Due to the concerted efforts of countless professionals, the majority of critical systems successfully made the transition to the year 2000 without major disruptions. However, the Y2K challenge highlighted the potential vulnerabilities of technology and underscored the importance of diligent planning, cooperation, and proactive problem-solving in the face of complex, large-scale technical issues.</p>
<p>Y2K serves as a historical example of the intersection between technology, public awareness, and global preparedness. The lessons learned from the Y2K experience continue to inform discussions about the resilience of digital infrastructure, the challenges of managing complex systems, and the necessity of anticipating and addressing potential risks in the digital age.</p>


:: virus [definition todo] {"position":"2249,1306","size":"100,100"}
Infect the user's playthrough with the VIRUS, so they get random BLUES and KETTLES.


:: viruses [definition todo] {"position":"1999,1606","size":"100,100"}
Virus images here for STUXNET and ILOVEYOU


:: meme [definition nobr] {"position":"2124,1606","size":"100,100"}
<p>The biologist Richard Dawkins introduced the term "meme" in his 1976 book <i>The Selfish Gene</i>. For him, a meme – from the Greek root <i>mimeme</i>, meaning imitation – is a "replicator" in the "soup of human culture," a "unit of cultural transmission, or a unit of imitation" <<cite "192" "Dawkins, Richard. The Selfish Gene.">>. His examples include "tunes, ideas, catch-phrases, clothes, fashions, ways of making pots or of building arches." A meme-complex, or "memeplex,"" is a collection of these memes that tend to replicate together. Crucially, not all memes are created equal: Dawkins suggests that “longevity, fecundity, and <<define "copying-fidelity" "Loss">> determine how well a unit of culture will replicate and spread through the meme pool <<cite "192" "Dawkins, Richard. The Selfish Gene">>. For many memeticists, these phrases and ideas both parasitize the mind and form it; as Daniel Dennett puts it in his 1991 book <i>Consciousness Explained</i>, “the haven all memes depend on reaching is the human mind, but a human mind is itself an artifact created when memes restructure a human brain in order to make it a better habitat for memes” <<cite "207" "Dennett, Daniel. Consciousness Explained.">> In other words, the meme perspective articulates a reflexive relationship between <<define "information" "Information">>-as-content and consciousness-as-form; individuals arise out of the collection of memes in their minds.</p>

<p>The term is commonly (and often interchangeably) used alongside <<define "viral" "Virus">> to describe units of information that spread from person to person across the Internet. Limor Shifman argues that the meme is the "best concept to encapsulate some of the most fundamental aspects of the Internet," providing a vocabulary to examine the “gradual propagation from individuals to society, reproduction via copying and imitation, and diffusion through selection and competition” that units of culture undergo <<cite "18" "Shifman, Limor. Memes in Digital Culture.">>. This approaches the way that ‘meme’ gets used online: as a way of describing the cultural flotsam of the Internet.</p>

<p>Michele Knobel and Colin Lankshear gloss this vernacular use of the term meme, which better describes the particular way in which memes operate online, "to describe the rapid uptake and spread of a 'particular idea presented as a written text, image, <<define "language 'move'" "Language Game">>, or some other unit of cultural stuff” <<cite "202" "Lankshear, Colin, and Michele Knobel. New Literacies.">>. The way that the meaning of the word meme has mutated, from Dawkins’ definition to this vernacular use, has been taken by Dawkins and others to be indicative of the way that memes themselves function; in a speech given at the Cannes Film Festival, Dawkins announced that "the very idea of the meme has itself mutated and evolved in a new direction. An Internet meme is a hijacking of the original idea. Instead of mutating by random chance […] Internet memes are altered deliberately by human activity. In some cases, this can take the form of genuinely creative art" <<cite "4:08" "Dawkins, Richard. Just for Hits.">>. Although this distinction is a helpful one, it elides the fact that many Internet memes are mutated not by humans but instead by <<define "computers" "AI">>, or by a collaboration between humans and machines. Still, the difference between a meme in the classic sense and an Internet meme is not as great as it might seem; indeed, the latter is primarily a subset of the former, and drawing a hard distinction between memes with digital material supports and memes with analogue supports is only helpful inasmuch as the difference between the two is instructive.</p>

For some examples of memes, see the <<excerpt "Meme Gallery">>.


:: Influenza [definition nobr GPT-3]

<p>"Influenza," commonly known as the flu, is a contagious respiratory illness caused by influenza viruses. It is characterized by a range of symptoms that can vary in severity, from mild to severe, and can lead to complications, especially in vulnerable populations. The flu viruses are classified into different types and subtypes, including influenza A, B, and C, based on their genetic makeup.</p>
<p>Flu symptoms typically include fever, cough, sore throat, runny or stuffy nose, body aches, fatigue, and headaches. In some cases, individuals may experience vomiting and diarrhea, although these symptoms are more common in children. The flu is often confused with the common cold due to the similarity of symptoms, but the flu tends to be more intense and may lead to more severe health outcomes.</p>
<p>Each year, seasonal flu outbreaks occur, primarily during the fall and winter months. The flu can spread through respiratory droplets when an infected person coughs, sneezes, or talks, as well as through contact with contaminated surfaces. Because the influenza virus can mutate and change over time, new strains can emerge, which is why flu vaccines are updated annually to match the most prevalent strains expected for the upcoming flu season.</p>
<p>Flu vaccination is a key preventive measure recommended by health authorities worldwide. The flu vaccine helps reduce the risk of infection and, even if an individual still contracts the flu, vaccination can often lead to milder symptoms and reduced risk of complications. Vaccination is especially important for certain groups, such as the elderly, young children, pregnant women, and individuals with underlying health conditions, who are at higher risk of severe flu-related complications.</p>
<p>While most people recover from the flu without any long-term effects, complications can arise, particularly in vulnerable individuals. These complications may include pneumonia, bronchitis, sinus and ear infections, and worsening of pre-existing medical conditions. Therefore, seeking medical attention and following recommended treatments is important, especially for those at higher risk.</p>
<p>In summary, influenza is a viral respiratory illness that can lead to a range of symptoms, with the potential for severe complications, particularly in certain populations. Annual flu vaccination, along with good hygiene practices, such as regular handwashing and covering coughs and sneezes, are essential strategies for reducing the spread of the flu and minimizing its impact on public health.</p>

:: Informatic Schematic [definition todo] {"position":"2004,1897","size":"100,100"}
More to be written here.


:: Benjamin’s aura [hs definition] {"position":"1615,2202","size":"100,100"}
"In even the most perfect reproduction, one thing is lacking: the here and now of the work of art--its unique existence in a particular place. It is this unique existence--and nothing else--that bears the mark of the history to which the work has been subject."

"The authenticity of a thing is the quintessence of all that is transmissible in it from its origin on, ranging from its physical duration to the historical testimony relating to it."

[[Walter Benjamin, "The Work of Art in the Age of its Technological Reproducibility," p21-22->Benjamin, Walter. "The Work of Art in the Age of its Technological Reproducibility."]]

:: Keyframes [definition] {"position":"3719,4368","size":"100,100"}
Per <a target="_blank" href="https://en.wikipedia.org/wiki/Key_frame">Wikipedia</a>, a key frame (or keyframe) in animation and filmmaking is "a drawing or shot that defines the starting and ending points of any smooth transition. These are called frames because their position in time is measured in frames on a strip of film or on a digital video editing timeline. A sequence of key frames defines which movement the viewer will see, whereas the position of the key frames on the film, video, or animation defines the timing of the movement. Because only two or three key frames over the span of a second do not create the illusion of movement, the remaining frames are filled with 'inbetweens'"

For animation, a keyframe can be thought of like a single snapshot of a stop-motion animation. Each keyframe is (generally) manually posed. This works differently than animation which leverages <<define "motion-capture data" "Motion-capture data">> to transcode captured <<define "meatspace" "Meatspace">> gestures into data that can be used to animate a model.

:: Thought Experiment [definition GPT-3]
<p>Thought experiments are hypothetical situations that allow us to explore what would happen if a particular principle were true, or a particular thing were the case. They are useful in philosophy and science, because they allow us to explore the implications of a particular idea without having to actually go through the process of making that idea a reality. In philosophy, the thought experiment is often used to explore the implications of a particular principle, or to show that a particular principle is false. In science, thought experiments are used to explore the implications of a particular theory, or to develop new theories.</p>

<p>Some common thought experiments in philosophy include the <<define "Chinese Room Argument">>, which was used by John Searle to show that computers cannot be said to understand language, and the <<define "Trolley Problem">>, which is used to explore the implications of different ethical theories.</p>

<p> Daniel Dennett's term "intuition pump" is closely related to the thought experiment; an intuition pump is a thought experiment that is designed to help us understand a particular concept by providing a concrete example of it. Intuition pumps are often used in philosophy and cognitive science to help us understand complex concepts like consciousness and free will. For more on intuition pumps, see Daniel Dennett's book <i>Intuition Pumps and Other Tools for Thinking</i>. </p>

<p> Works of science fiction often have thought experiments as their premises.<p>

:: Chinese Room Argument [definition] {"position":"1154,809","size":"100,100"}
<p>The Chinese Room Argument is a thought experiment that was first proposed by John Searle in 1980. It is designed to show that computers cannot be said to understand language. The argument goes as follows:</p>

<p>Suppose that I am locked in a room, and that I am given a set of rules in English that tell me how to respond to questions in Chinese. I do not understand Chinese, but I can follow the rules, and so I can give correct answers to questions in Chinese. Now, suppose that someone outside the room asks me a question in Chinese. I look up the rules, and I give them a correct answer. But do I understand Chinese? No, I do not. I am just following rules. Similarly, computers do not understand language, they just follow rules. Therefore, computers cannot be said to understand language.</p>

<p>The Chinese Room Argument has been the subject of a great deal of debate, and there are many different ways of interpreting it. For more on the Chinese Room Argument, see John Searle's book <i>Minds, Brains, and Science</i>. </p>

:: Trolley Problem [definition GPT-3]
<p>The <<excerpt "Trolley Problem">> is a thought experiment that is used to explore the implications of different ethical theories. The problem goes as follows:</p>

<p>You are driving a trolley, and you see that there are five people in the path of the trolley. You can either do nothing, and the trolley will kill the five people, or you can pull a lever, and the trolley will switch to a different track, killing one person. What should you do?</p>

<p>The trolley problem is often used to show that utilitarianism is the correct ethical theory. According to utilitarianism, the right thing to do is the thing that will produce the greatest amount of happiness for the greatest number of people. In this case, the right thing to do is to pull the lever, because it will produce more happiness overall. However, there are many different ways of interpreting the trolley problem, and it is not clear that it shows that utilitarianism is the correct theory. For more on the trolley problem, see Peter Singer's book <i>Practical Ethics</i>. </p>

:: Euthyphro Dilemma [definition GPT-3]
<p>The <<excerpt "Euthyphro Dilemma">> is a thought experiment that was first proposed by Socrates. It is designed to show that the traditional conception of piety is false. The problem goes as follows:</p>

<p>Euthyphro is a man who has been charged with impiety, and he is trying to defend himself. Socrates asks him to define piety, and Euthyphro says that it is "the doing of what is dear to the gods." Socrates then asks whether the gods love what is pious because it is pious, or whether it is pious because the gods love it. Euthyphro cannot give a satisfactory answer to this question, and so Socrates concludes that the traditional conception of piety is false. For more on the Euthyphro Dilemma, see Plato's dialogue <i>Euthyphro</i>. </p>

:: Zuhanden [definition todo]
Define this!

:: Vorhanden [definition todo]
Define this!

:: Narrative Self [definition nobr GPT-3]

<p>The "narrative self" is a psychological and philosophical concept that represents the unique and evolving sense of personal identity and continuity that individuals construct through the creation and interpretation of narratives. It suggests that human beings naturally shape their self-concept and understanding of their lives through the stories they tell about themselves.</p>
<p>At the heart of the narrative self is the idea that people organize their experiences, memories, and aspirations into coherent narratives that give their lives meaning and coherence. These narratives involve the weaving together of past events, present circumstances, and future aspirations into a continuous story that provides a sense of identity and purpose.</p>
<p>The narrative self can encompass various elements, including:
<ul>
<li><strong>Autobiographical Memory:</strong> Personal memories play a central role in shaping the narrative self. Individuals select, interpret, and prioritize memories that contribute to their self-concept and the story they tell about who they are.</li>
<li><strong>Agency and Goals:</strong> Narratives often involve accounts of one's actions, choices, and intentions. Individuals narrate their achievements, setbacks, and aspirations, reflecting their sense of agency and the pursuit of meaningful goals.</li>
<li><strong>Coherence and Consistency:</strong> Narratives strive to create a sense of coherence and consistency in one's life story. People seek to reconcile conflicts, contradictions, and ambiguities in order to present a unified sense of self.</li>
<li><strong>Transformation and Change:</strong> Narratives accommodate shifts and changes in identity over time. Individuals construct narratives that reflect personal growth, development, and adaptation to life's challenges.</li>
</ul>
<p>The narrative self has implications for psychological well-being, as individuals often find meaning and purpose in the stories they construct. Engaging in narrative practices, such as journaling, storytelling, and reflecting on personal experiences, can promote self-awareness, resilience, and a sense of coherence in the face of life's complexities.</p>
<p>While the narrative self emphasizes the active role individuals play in constructing their identities, it also acknowledges the social and cultural influences that shape the narratives people draw upon. Societal norms, cultural values, and shared narratives contribute to the frameworks within which individuals create their personal stories.</p>
<p>In summary, the narrative self is a dynamic and evolving representation of personal identity formed through the weaving together of life experiences into meaningful narratives. This concept underscores the role of storytelling in shaping how individuals understand, interpret, and convey their lives and sense of self.</p>


:: Meatspace [definition nobr]
<p>Meatspace is the analog inversion of <<define "cyberspace" "Cyberspace">>: the world of physical "meat suits" (that is, bodies). The term often attributed to William Gibson, who describes the meat/cyber binary in <i>Neuromancer</i> thusly:</p>

<p>"For Case, who’d lived for the bodiless exultation of cyberspace, it was the Fall. In the bars he’d frequented as a cowboy hotshot, the elite stance involved a certain relaxed contempt for the flesh. The body was meat. Case fell into the prison of his own flesh." <<cite "6" "Gibson, William. Neuromancer.">></p>

:: Cyberspace [definition nobr]
<p>"Cyberspace" is a now-dated term referring to the online world as the digital inversion of <<define "meatspace" "Meatspace">>. As Lincoln Dahlberg writes in a 1998 article, cyberspace is a "virtual meeting place" that, at that point, was seen as "providing the basis for the revitalisation of the public sphere and democracy" - in other words, a would-be utopian update to Jürgen Habermas's "public sphere" <<cite "1" "Dahlberg, Lincoln. Cyberspace and the Public Sphere: Exploring the Democratic Potential of the Net.">>. Dahlberg's article is prescient inasmuch as it identifies the consolidation of cyberspace under the aegis of capital, in the form of telecommunication and technology companies, as reason to be wary of over-utopian theorizing.</p>

<p>Chip Morningstar and F. Randall Farmer's piece in the 2003 <i>New Media Reader</i>, defines cyberspace less in terms of its technological support and more in terms of the "interactions among the actors within it" <<cite "664" "Morningstar, Chip, and Farmer, F. Randall. The Lessons of Lucasfilm's Habitat.">>. In this telling, cyberspace is first and foremost a "many-participant environment" where various sorts of actors come together, converse, and interact.</p>

<p>For myself, the term cyberspace brings to mind two platforms where I grew up - <<define "MUDs" "MUD">> and <<define "World of Warcraft">>. I spent hours of every day in these virtual worlds, inhabiting textual and graphical <<define "personae" "Persona">> with bodies radically different from my own and answering to names with no connection to my own. I made friends that I remain in contact with to this day; I was the best man at one such friend's wedding. On many days, I spent more time online than off, and the social behavior with which I gestured myself into being was platformed in this cyberspace.</p>

<p>Of course, this was a more radical idea in 2019 than it became in 2020, when many of the knowledge workers who I assume are the audience for this dissertation found themselves living their lives in cyberspace, struggling against the <<define "lossy" "Loss">> constraints of platforms like Zoom.</p>

:: Cyborg [definition nobr GPT-3]
<p>A "cyborg," short for "cybernetic organism," is a conceptual entity that merges the realms of <<define "meatspace" "Meatspace">> and <<define "cyberspace" "Cyberspace">>, blurring the boundaries between the physical and digital domains. Coined by Manfred Clynes and Nathan S. Kline in 1960, the term initially referred to the augmentation of human capabilities through technological enhancements, illustrating the potential for humans to transcend their biological limitations. Over time, the concept of a cyborg has evolved beyond mere physical adaptations, encompassing the symbiotic relationship between humans and technology.</p>
<p>Cyborgs embody a fusion of organic and artificial components, embodying a spectrum of forms from subtle technological augmentations to more elaborate integrations. Donna Haraway's influential essay "A Cyborg Manifesto" introduced the idea of cyborgs as beings that challenge traditional notions of gender, identity, and embodiment, suggesting that technology can dismantle oppressive social constructs. Haraway's work emphasized the subversion of established norms and the empowerment derived from embracing the hybrid nature of cyborg existence.</p>
<p>In contemporary contexts, the term "cyborg" encapsulates individuals who engage with digital environments, such as virtual reality, social media, and wearable technology, to extend their cognitive and communicative abilities. The prevalence of smartphones, smartwatches, and wearable fitness trackers has propelled the integration of technology into daily life, contributing to the normalization of cyborg-like experiences.</p>
<p>Cyborgs not only challenge the dichotomy between the physical and the digital but also raise ethical, philosophical, and sociopolitical questions about identity, privacy, agency, and the potential for exploitation by corporations and governments. As technology continues to advance, the notion of what constitutes a cyborg continues to expand, reflecting the evolving relationship between humans and the digital realm.</p>
<p>For instance, individuals who use brain-computer interfaces to control external devices or who implant microchips for convenience illustrate the contemporary cyborg sensibility, where the line between human and machine blurs, and the boundaries of self shift in intriguing and sometimes disconcerting ways.</p>
<p>In the intricate dance between human and machine, the concept of the cyborg provokes contemplation about the nature of existence, the malleability of identity, and the uncharted territories of a future where the organic and the synthetic intertwine.</p>

:: MUD [definition todo nobr]
<p>MUD stands for "Multi-User Dungeon" and describes a once-popular genre of multiplayer text-based roleplaying games that preceded massively multiplayer online RPGs like <<define "World of Warcraft">>. They worked a bit like a multiplayer version of early adventure games like Zork; users (often volunteers) wrote room descriptions, monster descriptions, in-world books, and indeed whole worlds, and then wrote characters to explore those worlds.</p>

<p>I would estimate that I spent around 3500 hours on MUDs between the age of 15 and 25; I met my first girlfriend on one, through out-of-character chats, and made many friends with whom I remain close. I spent around 1000 hours as Adrian Fripp, a very important druid and one-time king, and on many days spent more time as him than as Ken Alba. Spending that much time as someone else necessarily changes the player; I would not be who I am without the time I spent growing up in this particular kind of world. Without MUDs, many of the questions that have animated my research into performance and identity would never have occurred to me.</p>

:: Avatar [definition todo ]
An avatar is the electric body one projects oneself into and through in order to exist on digital platforms. Avatars are often, but not always, graphical in nature, and range from the simple "@" symbol of 1980's <i>Rogue/i> and other early dungeon crawlers to the infinitely customizable bodies available in contemporary video games like <i>Dragon Age</i> or <i>VR Chat</i>. 


:: Persona [definition nobr]
<p>The word "person" stems etymologically from the Latin <i>persona</i>, meaning "mask used by a player / character in a play – or the part played by a person in life, character, role, position" <<cite "OED" "Oxford English Dictionary">> "Person" and "persona" suggest two ways of understanding personhood: in one, the subject is their individuality, their mind, their personality – in a word, their self. In the other, a person is constituted by the way their identity is performed and perceived by other people – a sort of constructed, intersubjective social identity made up by the masks they wear. This decentered subject has been the object of critical study for decades now. Judith Butler, in particular, has provided insight into the way a subject is constituted by their iterated performative acts, the organ of which is the body. Her argument is compelling, but as we migrate to new, digital worlds, it makes less sense to privilege the material body over the <<define "avatar" "Avatar">> as the instrument with which one plays oneself.</p>

:: Section 107 of the Copyright Act [definition] {"position":"4194,2268","size":"100,100"}
"107. Limitations on exclusive rights: Fair use
Notwithstanding the provisions of sections 106 and 106A, the fair use of a copyrighted work, including such use by reproduction in copies or phonorecords or by any other means specified by that section, for purposes such as criticism, comment, news reporting, teaching (including multiple copies for classroom use), scholarship, or research, is not an infringement of copyright. In determining whether the use made of a work in any particular case is a fair use the factors to be considered shall include—

(1) the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes;

(2) the nature of the copyrighted work;

(3) the amount and substantiality of the portion used in relation to the copyrighted work as a whole; and

(4) the effect of the use upon the potential market for or value of the copyrighted work.

The fact that a work is unpublished shall not itself bar a finding of fair use if such finding is made upon consideration of all the above factors."

:: data into information [definition] {"position":"3721,5103","size":"100,100"}
The most naive way of expressing the distinction between <<define "data" "Data">> and <<define "information" "Information">> is to rely on Luciano Floridi's definition of information as "meaningful, well-ordered data" <<cite "8" "Floridi, Luciano. Information: A Very Short Introduction.">>. In this telling, data are the raw material out of which instrumentally useful information is made. In other words, as Lisa Gitelman and Virginia Jackson put it in the introduction to <i>'Raw Data' is an Oxymoron</i>, "data are apparently before the fact" <<cite "2" "Gitelman, Lisa. 'Raw Data' is an Oxymoron.">>.

Instrumentally, then, we can think about data as 'preprocessed' information that needs to be mined and refined until it's meaningful, like the raw sense data of [[Kantian cognition->Critique of Judgment]] that precedes the operations of the imagination and the understanding. Zeroes and ones, serialized dictionaries, and electrical variances become lights on a screen that make words, images, and other media with meaning; the former is data, the latter information.

However, as Gitelman's title suggests, this definition fails to account for the way in which data have to be "imagined <i>as</i> data to exist and function as such, and the imagination of data entails an interpretive base" <<cite "3" "Gitelman, Lisa. 'Raw Data' is an Oxymoron.">> -- and, as research and news stories on everything from cameras that can't see people of color to algorithms that re-enact redlining have demonstrated, an interpretive base is awfully close to an interpretive bias. Data cannot be prior to interpretation because its extraction is accomplished by human-made tools that can reflect the biases, blind spots, and bad motives of their engineers. Garbage in, garbage out.


:: Glitch [definition todo] {"position":"3719,2968","size":"100,100"}
The <span class="glitch" data-text="glitch">glitch</span> here is defined as both a technical term and as an aesthetic moment.

From a technical perspective, a <span class="glitch" data-text="glitch">glitch</span> is, per the [[OED->Oxford English Dictionary]], "A surge of current or a spurious electrical signal; also, in extended use, a sudden short-lived irregularity in behaviour."

From an aesthetic perspective, however, the <span class="glitch" data-text="glitch">glitch</span> is a moment when less becomes more, when the lossy contingencies of digital being paradoxically give rise to the production of something novel. This is often accompanied by a shift in the hermeneutic categorization of <<define "signal" "Signal">> and <<define "noise" "Noise">> as discrete; instead, under the sign of the <span class="glitch" data-text="glitch">glitch</span>, the two switch places, intermingle, and become a new signal. 

In the context of informational performativity, we might think about the <span class="glitch" data-text="glitch">glitch</span> as a mode of resistance to binary oppositions imposed by platforms. This passage requires expansion.

See [[Blue Kettle->Case Study: BLUE KETTLE]], [[Menkman's Glitch Studies Manifesto->Menkman, Ross. Glitch Studies Manifesto.]], and my discussion of the <span class="glitch" data-text="glitch">glitch</span> in the context of [[Kant's account of aesthetic experience of beauty->Kant's Glitch]].


:: transcoding [definition] {"position":"3719,2568","size":"100,100"}
"In new media lingo, to 'transcode' something is to translate it into another format. The computerization of culture gradually accomplishes similar transcoding in relation to all cultural categories and concepts. That is, cultural categories and concepts are substituted, on the level of meaning and/or the language, by new ones which derive from computer’s ontology, epistemology and pragmatics. New media thus acts as a forerunner of this more general process of cultural re-conceptualization." <<cite "45" "Manovich, Lev. The Language of New Media.">>


:: Loss [definition todo] {"position":"3602,2569","size":"100,100"}
<<define "Data">> takes up space to store and bandwidth to transmit. By utilizing compression algorithms, the amount of space that data takes up can be reduced. However, that compression is seldom a lossless - or reversible - process. Instead, data is ordinarily lost during compression. These compression algorithms undergird the systems by which media is transmitted online. 

Loss is not unique to digital transcoding. Consider the process by which a 70mm film is transcoded into a digital format. This process can be 'lossless' inasmuch as it produces an enormous video file that, in theory, could be used to print a new 70mm film. However, as the protestations of film-first afficionadoes attest, analog media is continuous where digital media is not; nuances are often lost. 

When a streamer watches a movie on, say, Netflix, the already-lossy digital file is compressed based on their internet speed. 


:: Unity [definition] {"position":"3594,3568","size":"100,100"}
<a target="_blank" href="https://unity.com/">Unity</a> is a popular modern game engine that stands out for its flexibility. A single project created in Unity can generally be exported to many different platforms -- Mac, Windows, Android, Web, VR, and others. Creators use a combination of the programming language C# and Unity's GUI to create their game. I have used Unity to create [[EndlessGame->Case Study: ENDLESSGAME]] and [[Almost to the Tick->Case Study: ALMOST TO THE TICK]].


:: virtual reality [definition nobr GPT-3] {"position":"3469,3568","size":"100,100"}
<p>The term "virtual reality" (VR) was coined in the 1980s by Jaron Lanier, one of the earliest developers of VR technology and the founder of VPL Research, a now-defunct company that was instrumental in the development of VR technology. He defined it as "a computer-generated simulation of a three-dimensional image or environment that can be interacted with in a seemingly real or physical way by a person using special electronic equipment" <<cite "Lanier" "Lanier, Jaron. Virtual Reality.">>. This definition is still in use today, although it has been expanded to include non-computer-generated simulations, such as those produced by 360-degree cameras.</p>

<p>Lanier's definition is helpful in understanding what VR is, but it is also important to understand what VR is not. VR is not, as is often assumed, simply a computer-generated simulation of reality; it is a simulation that is designed to be interacted with in a physical way. This physicality is essential to the VR experience; without it, VR would simply be a three-dimensional movie. The interaction can take many forms, but it must be more than simply looking at the simulation; it must be an embodied experience. This is why VR technology is often referred to as "immersive technology."</p>

<p>The term "virtual reality" is sometimes used interchangeably with "augmented reality" (AR), but the two are not the same. AR is a technology that superimposes computer-generated images on the real world, while VR is a technology that replaces the real world with a computer-generated simulation. AR is often used for navigation, while VR is often used for entertainment. For more on AR, see the <<excerpt "Augmented Reality">>.</p>

<p>Most versions of the metaverse take place in a kind of VR.</p>


:: Motion-Capture Data [definition nobr GPT-3]

<p>"Motion-capture data" refers to the digital information captured and recorded from real-world movements and actions, typically using specialized technology known as motion-capture systems. These systems utilize various sensors, cameras, and markers to track and record the motions of objects or living beings, such as humans or animals, in order to create accurate and realistic representations of movement in virtual environments.</p>
<p>The process of capturing motion involves placing markers or sensors on key points of the subject's body, which are then tracked as the subject moves. High-speed cameras or other sensor technologies record the spatial positions and orientations of these markers over time, generating a dataset that represents the intricate details of the subject's motion. This data can then be processed and translated into a digital format that can be applied to virtual characters, models, or animations.</p>
<p>Motion-capture data has a wide range of applications across various industries, including entertainment, sports, medicine, and research. In the entertainment field, motion-capture technology is frequently used in filmmaking and video game production to create lifelike character animations. Actors wearing motion-capture suits perform actions, and their movements are captured and mapped onto digital characters, enhancing realism and immersion in visual media.</p>
<p>In sports, motion-capture data is used to analyze athletes' movements, helping coaches and researchers study techniques, improve performance, and prevent injuries. In medical settings, motion-capture technology aids in assessing patients' physical movements and tracking their progress during rehabilitation and therapy programs. Additionally, researchers use motion-capture data to study biomechanics, cognitive processes, and human behavior in diverse fields of study.</p>
<p>One of the challenges associated with motion-capture data is the sheer volume of information generated during the capture process. Raw motion-capture data may require processing to remove noise, calibrate measurements, and align data across multiple sensors or cameras. Moreover, accurately applying the captured data to virtual models or characters requires specialized software and techniques to ensure realistic and seamless animation.</p>
Motion capture http://mocap.cs.cmu.edu/ . This passage requires expansion.

:: Cognition [definition GPT-3]
<p>Cognition is a catch-all term for the various ways that humans process information. It includes everything from basic sensory processing to long-term memory to complex thought.</p>
<p>Cognition is often used as a synonym for "consciousness," but the two terms have different connotations. "Consciousness" refers to subjective experience, while "cognition" refers to the more objective, scientific study of the mental processes that underlie it.</p>


:: Memory [definition GPT-3]
<p>The word "memory" is derived from the Latin <i>memoria</i>, meaning "recollection, memory, remembrance; a thing worth remembering, a memorial; a tomb or monument" <<cite "OED" "Oxford English Dictionary">>. The root of this word, <i>memor</i>, means "to remember, to call to mind; to mention, record, celebrate in memory; to be mindful of; to keep in mind, to keep in view" <<cite "OED" "Oxford English Dictionary">>. Memory, then, is the act or faculty of remembering, or the power of retaining knowledge acquired in the past, and is often used interchangeably with "recollection." 

<p>The word "memory" is also used to describe the physical apparatus through which we remember. This usage is derived from the Latin <i>memoria</i>, meaning "a store-house, a repository; a place where something is deposited for safe keeping" <<cite "OED" "Oxford English Dictionary">>. In this sense, memory is a storehouse of information, and the act of remembering is the act of retrieving this information. This usage is common in computing, where data is stored in memory – in RAM, for example – and retrieved when needed. Indeed, the word "memory" is often used to describe the capacity of a computer to store information.</p>

<p>The word "memory" is also used to describe a record of the past, either in the form of an account or a physical object. This usage is derived from the Latin <i>memoria</i>, meaning "remembrance, memory; a thing worth remembering, a memorial; a tomb or monument" <<cite "OED" "Oxford English Dictionary">>. In this sense, memory is a way of preserving the past, and the act of remembering is the act of keeping this record alive.</p>

:: Cognitive Loops [definition todo]
Define this!

:: Kant's Glitch [definition todo]

For Kant, power of judgment depends on the cognitive faculties: the sensibility (which is subserved by imagination) and the understanding. A brief digression: in the Critique of Judgment, Kant states that the two cognitive faculties are the imagination and the understanding; elsewhere, they are sensibility and the understanding, and the imagination is included in the sensibility. Because those two faculties are the ones in play for apprehension of the beautiful through a judgment of taste, this study will focus primarily on them. That is: when I refer to the cognitive faculties, I mean imagination and understanding. Sensibility is, more or less, the way we take in particulars from the world. This intuitive appropriation of the world itself is not governed by concepts yet – it’s just the raw input, before we’ve made any sense of it. The imagination synthesizes the raw input received from the sensibility into something like an image (or, in Kant’s words, “combines the manifold of intuition” (62)), which then gets passed over to the understanding. The understanding is the “law-giver,” which takes the processed image from the imagination and subsumes it under concepts, including the categories of the understanding (or, again in Kant’s words, provides “the unity of the concept uniting the [component] presentations (62)). There is some confusion here, depending on what Kant you’re reading: sometimes, it seems like the imagination synthesizes the input of the sensibility by applying the categories of the understanding; sometimes, it seems more like the imagination is the step just before the understanding, which gives the understanding the picture that the understanding makes sense of. I will use an example to illustrate the process as I understand ig.
For example, let’s take a chair. When I look at the chair, some stuff happens with light and my eyes are barraged with sensory input. This gets brought into my mind through the sensibility, which includes intuition. My imagination takes those particulars and synthesizes it into something that the understanding can work on: I have the image of the chair, but it hasn’t yet resolved into anything that makes any kind of sense. Think of it like letters to a dead language: the letters is there, but they mean anything until the understanding works on it. In normal cognition, the chair is then subsumed under concepts, especially the categories of the understanding – transcendental concepts which structure phenomenal reality. This is when the dead language starts to make words. I can make out the shape of the chair, I see that it resembles other chairs, and so on. The object of my perceptions is subsumed under concepts and becomes an intelligible element of my phenomenal existence. This is, in brief, how normal cognition works. And sometimes we like things that we cognize regularly: through the “taste of sense,” (58) we arrive at pleasure, and as a result we find the object agreeable (although, importantly, the agreeable is not universal and instead “everyone has his own taste” (55)).
The beautiful is something very different. It is never subsumed under a concept: indeed, this is one of the defining characteristics of the beautiful. It is also always disinterested. Cognition begins as normal: we receive sensory input through the sensibility. However, things change when the faculty of the imagination receives those particulars: rather than working in conjunction with the understanding to synthesize the image and subsume it under concepts, during a judgment of taste (how we arrive at the beautiful) intuitions are not subsumed under concepts. Instead, the imagination in its freedom from concepts “harmonizes with the understanding in its lawfulness” (151). Kant calls this harmonization “free play,” and states that “a judgment of taste must rest upon the pure sensation of both the imagination in its freedom and the understanding with its lawfulness, as they reciprocally quicken each other, i.e. upon a feeling that allows us to judge the object by the purposiveness that the presentation has insofar as it furthers the cognitive powers in their free play” (151). Pleasure in the sensation of the free play between imagination and understanding is the subjective experience of purposiveness in the presentation of an object – not the object itself – without any purpose and hence as “the mere form of purposiveness” (66). This pleasure is beauty: “Beauty is an object’s form of purposiveness insofar as it is perceived in the object without the presentation of a purpose” (84).
Another example might be helpful. Let’s take a rose. A woman sees, breathes deeply around, and touches this rose. She receives, through her senses and her sensibility, the raw data of the rose – that stuff goes into her mind. Her imagination is there to catch that data and start to synthesize it into something. So far, so good: normal cognitition is at play, and we’re at the same place here as we were with the chair. But her imagination, playing with the bits and pieces of ununified particulars she’s supposed to make into something – say, a chair – is baffled by the configuration of the bits. She goes to the understanding for help – normally, the imagination is in a reciprocal, collaborative role with the understanding in cognition and it’s difficult to fully separate the two – and the understanding reaches for the concepts. You can think about these concepts like measuring implements that allow the understanding to turn raw data into the phenomenal world. But something happens. The concepts can’t subsume the particulars; the rose cannot be measured (or, at least, some dimension of the rose cannot be measured). After a moment of trying, the understanding drops her ruler and starts just playing a game with the imagination. And instead of getting “rose,” the woman in whom all of this anthropomorphized cognition is taking place gets the sensation of free-play, which is beautiful. The rose is beautiful because, when the woman looked at it, it sent her imagination and her understanding into free play with one another, and so she experienced the sensation of beauty. 
It’s crucial to note here where ‘beauty’ is. On the one hand, beauty seems to be tied up in the object inasmuch as there are beautiful objects. However, Kant repeatedly says that the experience of beauty is subjective – or, at least, that the reflective judgment on the experience of free play which makes the mind aware of pure purposiveness, which is to say beauty, takes place in the subject. The apparent contradiction resolves, more or less, when we keep in mind the cognitive process outlined above: the object spurs the imagination and the understanding into free-play, but the free-play is the sensation of beauty. The sensation of beauty inheres in the subject, even if the object is beautiful. And the judgment of taste that results in beauty is always reflective: it is not a function of the object but instead of reflection upon the sensation of freeplay. This is where we get the “subjective” part of the definition of beauty as the subjective universal. 
But what about universality? Kant says repeatedly that beauty is “what, without a concept, is liked universally” (64). Some other things are universal in Kant’s system; the moral law, for example. If a thing can be made universal through the operation of reason, then that thing is objectively – or logically – universal. However, the tie between ‘universal’ and ‘objective’ is a common one. ‘Subjective’ is a byword for non-universal, conditional, all in the head of the subject and not tethered to the real universe, so “subjective universal” seems to be a contradiction. Beauty is clearly subjective inasmuch as the experience of beauty, and reflection on that experience which yields an awareness of pure purposiveness, takes place within the subject. How can something be universal that takes place within the subject?
Kant answers this question by appealing to what he calls a common sense. On the one hand, Kant says that a common sense is “the effect arising from the free play of our cognitive powers” (87) – which sounds an awful lot like the sensation of the beautiful. But that’s tautological – it doesn’t get us much deeper in? The translator’s note is again helpful here: it states that a “common sense” is the presupposition, a priori, that “taste and the feeling by which it judges is common to everyone” (lv). Because the liking of the beautiful is “our consciousness of... the form’s purposiveness for that harmony” (lx) and because the harmony “can be assumed to be the same for everyone,” we can assume that taste is grounded on a common sense. Even this argument has a ring of circularity to it, though. The necessary addition to the system – the final piece to this specific puzzle – is the notion of universal communicability, on which common sense and the possibility of a subjective universal depends.
Common sense is “the necessary condition of the universal communicability of our cognition, which must be presupposed in any logic and any principle of cognitions that is not skeptical” (88) and that “only under the presumption of such a common sense, I maintain, can judgments of taste be made” (87). Common sense is thus grounded on the idea of universal communicability and is a necessary element of the system if we are to escape from skepticism. But how does Kant justify universal communicability – beyond simply rejecting the skeptical hypothesis by appealing to experience, which isn’t his style? First of all, the bulk of Kant’s rejection of skepticism is in the first Critique; bootstrapping out of Descartes is beyond the scope of this paper. Kant assumes on this basis that we can communicate our empirical cognitions and our judgments with other people, and that we are understood when we do so. And because we can communicate our cognitions and our judgments, we can assume that “the cognitive powers presupposed by this common understanding are shared universally as well” (lx). In other words: we assume cognitions can be communicated because we are not skeptical. In order for us to be able to communicate cognitions,  the “attunement of the cognitive powers required for cognition in general” – the functional relationship between them that turns the particulars of the outside world into phenomenal reality / cognition – must also be universal communicable. This universally communicable functional relationship between the cognitive powers is the subjective condition of the process of cogntion, and is necessary in order for us to have cognition (88). Kant restates this later on in the Critique, approaching the question from a slightly different angle:
“The aptitude that human beings have for communicating their thoughts to one another requires that imagination and understanding be related in such a way that concepts can be provided with accompanying intuitions, and intuitions in turn with accompanying concepts, these intuitions and concepts joining together to form cognition... only where the imagination is free when it arouses the understanding, and the understanding without using concepts puts the imagination into a play that is regular, does the presentation communicate itself not as a thought but as the inner feeling of a purposive state of mind.” (163)
The attunement of the cognitive powers (imagination and understanding) varies depending on the objects given: imagination and understanding behave differently when they’re processing a chair than when they’re processing a jar of marmalade, for example. But because cognitions can be communicated, we can assume that the mental state of taking in marmalade and the mental state of taking in a chair – the attunement of the faculties which gives rise to the phenomenal world of chair or marmalade – is also communicable. 
Why does this mean that everyone ought to judge the same things to be beautiful? Beauty is a special case because, as we’ve mentioned, it does not depend on concepts. According to Kant, there is “one attunement” – one particular kind of input – “in which this inner relation is most conducive to the (mutual) quickening of the two mental powers with a view to cognition (of given objects) in general.” This is determined by feeling, rather than concepts: this “one attunement” is the experience of the beautiful. Because it is still an attunement of the cognitive faculties, which we’ve already proven are universally communicable if cognitions are to be communicated at all, it is universally communicable. It depends not on the individual, but on the sensation of the attunement of the imagination and understanding – free play. 
The imagination and the understanding interact with one another by a set of rules, grounded in the constitution of the mind – “an original contract dictated by our very humanity” (164), and because this rule is standard and valid for every human, the same input going into the same cognitive apparatus will produce the same sensation of beauty. This is necessary for cognition to be universally communicable and is the ground of the possibility of beauty as a subjective universal. It is subjective because the feeling of beauty inheres in the subject rather than in the object; it is universal because attunement of the understanding and the imagination are bounded by the same parameters in every human, and the free play of those cognitive faculties is a common sense to everyone: the sensation of pure purposiveness (Kant calls this the “universality of the subjective conditions for judging objects” (62)). This is why Kant can say that the person who proclaims something to be beautiful “requires the same liking for others” and judges “not just himself but for everyone” (55). In other words, perhaps dissatisfyingly, Kant states that “We must be entitled to assume a priori that a presentation’s harmony with these conditions of the power of judgment is valid for everyone” (155) because we’re able to talk to each other.
But people clearly do not always agree on what is beautiful. This is not a contradiction, according to Kant, because of the specifically conditional nature of the injunction towards agreement that the beholder of the beautiful posits. Kant states that “whoever declares something to be beautiful holds that everyone ought to give his approval to the object at hand and that he too should declare it beautiful” (86). The ought here, in an aesthetic judgment – a judgment about the beautiful – is merely conditional, and “the common sense... is a mere ideal standard” (89).  If I think this mountain is beautiful, it’s because I take in the mountain (which is common to everyone) through my sensibility (which is common to everyone) and then my imagination and understanding get quickened into free play (the conditions of which are common to everyone, according to common sense). 
Hence “we solicit everyone else’s assent because we have a basis for [the aesthetic judgment] that is common to all” (86). However, because we can’t be sure that instance – here, the mountain – has been “subsumed” – it’s possible that someone else could not experience the mountain as beautiful. What is on trial is the claim that beauty has on everyone’s liking, not the liking itself, because the liking itself could be conditioned by exterior factors like interest. Presuming that taste is deployed properly, that the subjects in question are properly disinterested, the cognitive faculties are harmonizing with one another properly, and the concepts are not in play (for concepts of the object cannot be involved in a judgment of the beautiful) the subject who judges something to be beautiful “cannot help judging that it must contain a basis for being liked [that holds] for everyone” (54).
Because taste isn’t always deployed properly, if we want universal agreement on questions of the beautiful we still have a role for the critic, who should “investigate our cognitive powers and what these tasks perform in these judgments” and “clarify by examples the reciprocal subjective purposiveness” whose form in a presentation is “the beauty of the object of this presentation” (150). The critic’s job is made more difficult because the beautiful cannot be subsumed under concepts of the object. Consequently, “there can be no rule by which someone could be compelled to acknowledge that something is beautiful” (59). There’s a tension here: on the one hand, the critic can help us figure out our cognitive powers, understand purposiveness, and become disinterested; on the other hand, because beauty is always subjective as well as being universal, we always want to submit the object to our own eyes – indeed, we have to. 
So taste is autonomous, because it is subjective, but the object of taste – the beautiful – is objective. We can talk to one another about taste – it is “precisely what stands most in need of examples regarding what has enjoyed the longest-lasting approval” (147) and in doing so hone our taste, make ourselves more receptive to the proper attunement of the cognitive faculties that is beauty. But, for Kant, the beautiful is only of empirical interest in society. Taste in society is “an ability to judge whatever allows even our feeling to everyone else” and is hence “a means of furthering something that everyone’s natural inclination demands [i.e., sociability]” (163). Because beauty is the reflective awareness of the pure purposiveness in free play, freedom, harmony, and so on, and because that feeling of beauty is the same in all people, beauty drives us to seek out others who agree with us. We claim that they should be able to because if they can feel what we can feel – and they can, if only their taste is operating correctly – we would have confirmation of our judgment of taste. Society hus operates as a sort of empirical testing-ground for our judgments of the beautiful. The beautiful confirms our place in society because it underlines the universal constitution of the human mind, with its drive towards free play, and the person who judges an object beautiful wants to share that with others.  


:: Algorithm [definition nobr GPT-3]
<p>An algorithm is a set of instructions for a computer to follow. 

Algorithms are everywhere. They are the set of instructions that tell a computer how to do a task. For example, the instructions that tell a computer how to add two numbers together are an algorithm. Algorithms are also the set of instructions that tell a computer how to sort a list of numbers from smallest to largest. And algorithms are the set of instructions that tell a computer how to find the shortest path from one point to another.</p>

<p>Algorithms can be very simple, or they can be very complex. The instructions for adding two numbers together are a very simple algorithm. The instructions for finding the shortest path from one point to another are a very complex algorithm.</p>

<p>In this report, I use the term algorithm to refer to any set of instructions for a computer to follow. This includes both simple algorithms and complex algorithms.</p>


